# -*- coding: utf-8 -*-
"""Attention Mechanism Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MG3c47NG6YUozJRJmgxXBuDnj6WxqaaL
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
import tensorflow as tf
from keras.layers import Input, Dense, Dropout, Attention
from keras.models import Model
from keras.optimizers import Adam

# Load the KDD Cup 1999 dataset

url = "/content/drive/MyDrive/data sets/kddcup99.csv"

df = pd.read_csv(url)
print(df.head())
# Encode categorical features
categorical_features = df.select_dtypes(include=['object']).columns
for feature in categorical_features:
    encoder = LabelEncoder()
    df[feature] = encoder.fit_transform(df[feature])

# Split features and labels
X = df.drop(columns=['label'])
y = df['label']

# Normalize numerical features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the input shape
input_shape = (X_train.shape[1],)
print("DSF",input_shape)
# Define the input layer
input_layer = Input(shape=input_shape)

# Define the layers of the model
dense_layer1 = Dense(64, activation='relu')(input_layer)
dense_layer2 = Dense(64, activation='relu')(dense_layer1)

# Apply Attention mechanism
attention_layer = Attention()([dense_layer1, dense_layer2])

# Output layer
output_layer = Dense(len(df['label'].unique()), activation='softmax')(attention_layer)

# Create the model
model = Model(inputs=input_layer, outputs=output_layer)

# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.summary()
# Train the model
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))

from sklearn.metrics import f1_score

# Convert predictions to class labels
predictions = model.predict(X_test)
predicted_classes = predictions.argmax(axis=-1)

# Calculate F1 score
f1 = f1_score(y_test, predicted_classes, average='macro')
print('F1 Score: {:.2f}'.format(f1))

from sklearn.metrics import accuracy_score

# Calculate accuracy
accuracy = accuracy_score(y_test, predicted_classes)
print('Accuracy: {:.2f}'.format(accuracy))

from sklearn.metrics import classification_report

# Assuming `predicted_classes` are the predicted labels from your model
# and `y_test` are the true labels

# Generate classification report
report = classification_report(y_test, predicted_classes)

print(report)

